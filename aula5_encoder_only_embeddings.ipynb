{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5684b413",
   "metadata": {},
   "source": [
    "# Aula 5: Gerando Embeddings com Modelo Encoder-Only\n",
    "\n",
    "Este notebook demonstra como carregar um modelo encoder-only (ex: BERT) para gerar embeddings de sentenças de uma coleção de documentos. Compatível com Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d3633",
   "metadata": {},
   "source": [
    "## 1. Instalar e Importar Bibliotecas Necessárias\n",
    "\n",
    "Execute a célula abaixo para garantir que todas as bibliotecas estejam instaladas (especialmente no Colab)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bdbc8",
   "metadata": {},
   "source": [
    "> **Nota:** Os documentos separados por similaridade estão na pasta `Documentos Aula 5/` deste repositório. No Google Colab, faça o upload dos arquivos manualmente para processá-los."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00f90ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar bibliotecas no Colab, se necessário\n",
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !pip install transformers torch numpy\n",
    "\n",
    "# Importar bibliotecas essenciais\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f6e724",
   "metadata": {},
   "source": [
    "## 2. Carregar o Modelo Encoder-Only para Embedding\n",
    "\n",
    "Aqui, vamos carregar um modelo encoder-only (exemplo: DistilBERT) e seu tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defina o nome do modelo encoder-only (pode ser alterado para outro modelo compatível)\n",
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "# Carregar tokenizer e modelo\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Usar GPU se disponível\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae579c75",
   "metadata": {},
   "source": [
    "## 3. Preparar a Coleção de Documentos\n",
    "\n",
    "Defina uma lista de sentenças ou carregue um conjunto de documentos para gerar os embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60bad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de coleção de sentenças\n",
    "documentos = [\n",
    "    \"O modelo BERT é muito utilizado para embeddings.\",\n",
    "    \"Transformers revolucionaram o processamento de linguagem natural.\",\n",
    "    \"O PyTorch é uma biblioteca popular para deep learning.\",\n",
    "    \"Embeddings de sentenças são úteis para busca semântica.\",\n",
    "    \"Modelos encoder-only são eficientes para tarefas de classificação.\"\n",
    "]\n",
    "\n",
    "# Você pode substituir a lista acima por um carregamento de arquivo/texto, se desejar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a1222",
   "metadata": {},
   "source": [
    "## 4. Gerar Embeddings para Cada Sentença\n",
    "\n",
    "Utilize o modelo e o tokenizer para gerar embeddings para cada sentença da coleção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983dde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar embedding de uma sentença\n",
    "\n",
    "def gerar_embedding(sentenca, tokenizer, model, device):\n",
    "    inputs = tokenizer(sentenca, return_tensors='pt', truncation=True, padding=True)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Usar o embedding do [CLS] token (primeiro token)\n",
    "        embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy().flatten()\n",
    "    return embedding\n",
    "\n",
    "# Gerar embeddings para todas as sentenças\n",
    "embeddings = np.array([\n",
    "    gerar_embedding(sent, tokenizer, model, device) for sent in documentos\n",
    "])\n",
    "\n",
    "print(f\"Shape dos embeddings: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbfdc6c",
   "metadata": {},
   "source": [
    "## 5. Visualizar e Salvar os Embeddings\n",
    "\n",
    "Visualize exemplos dos embeddings gerados e salve-os para uso posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc9ded5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar os embeddings das primeiras sentenças\n",
    "for i, sent in enumerate(documentos):\n",
    "    print(f\"Sentença: {sent}\")\n",
    "    print(f\"Embedding (primeiros 5 valores): {embeddings[i][:5]}\")\n",
    "    print()\n",
    "\n",
    "# Salvar os embeddings em arquivo .npy\n",
    "np.save('embeddings_aula5.npy', embeddings)\n",
    "print(\"Embeddings salvos em 'embeddings_aula5.npy'\")\n",
    "\n",
    "# Opcional: salvar em CSV\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(embeddings, index=documentos)\n",
    "df.to_csv('embeddings_aula5.csv')\n",
    "print(\"Embeddings salvos em 'embeddings_aula5.csv'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
